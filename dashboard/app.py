import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import streamlit as st
from pipeline.orchestrator_graph import build_sentinel_graph

st.set_page_config(page_title="Sentinel", layout="wide")

st.title("ğŸ›¡ï¸ SENTINEL â€” Semantic Drift Guardian")
st.markdown("Detects drift between **contract intent** and **system behavior**")

document_text = st.text_area(
    "ğŸ“„ Contract / SLA Text",
    "The service response time shall not exceed 100 milliseconds."
)

logs = st.text_area(
    "ğŸ“Š Runtime Logs",
    "INFO service-a avg_response_time=150ms"
)

if st.button("ğŸš€ Run Sentinel"):
    graph = build_sentinel_graph()

    initial_state = {
        "document_text": document_text,
        "logs": logs,
        "source_file": "service_a_contract.txt",
        "service": "service_a"
    }

    result = graph.invoke(initial_state)

    st.subheader("ğŸ§  Extracted Intent")
    st.json(result["intent"])

    st.subheader("ğŸ‘ï¸ Observed Behavior")
    st.json(result["behavior"])

    st.subheader("âš ï¸ Drift Analysis")
    st.json(result["drift"])

    st.subheader("ğŸ¯ Action")
    st.json(result["action"])

    # -------------------------------
    # ğŸ§© Decision Explanation
    # -------------------------------
    st.subheader("ğŸ§© Decision Explanation")

    intent = result["intent"]
    behavior = result["behavior"]
    drift = result["drift"]
    action = result["action"]

    st.markdown(f"""
### Why was this action taken?

**ğŸ“œ Expected behavior (contract)**  
- `{intent.get("metric")} â‰¤ {intent.get("threshold")} {intent.get("unit")}`

**ğŸ“Š Observed behavior (runtime)**  
- `{behavior.get("observed_value")} {behavior.get("unit")}`

**âš ï¸ Reasoning**
- Semantic drift detected between documented intent and live behavior  
- Severity classified as **{drift.get("severity", "").upper()}**

**ğŸ¤– Autonomous Action**
- `{action.get("action")}` with priority `{action.get("priority")}`
""")

    # -------------------------------
    # ğŸ“ˆ Decision Confidence
    # -------------------------------
    evaluation = result.get("evaluation")

    st.subheader("ğŸ“ˆ Decision Confidence")

    if evaluation:
        st.metric(
            label="Confidence Score",
            value=evaluation["confidence_score"],
            delta=evaluation["confidence_level"].upper()
        )

        with st.expander("ğŸ§  Why Sentinel Is Confident"):
            st.write(evaluation["rationale"])
    else:
        st.info("No confidence evaluation available.")
